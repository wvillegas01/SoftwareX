import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import pickle
from datetime import datetime
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Dropout
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error
from tensorflow.keras.optimizers import SGD
from sklearn import metrics
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
from prettytable import PrettyTable
import matplotlib.dates as mdates
import matplotlib.ticker as mticker
from tensorflow.keras.callbacks import EarlyStopping


#Load data
data = pd.read_csv('data_source.csv')

#Convert the date column to numeric values
data['date'] = pd.to_datetime(data['date']).apply(lambda x: x.toordinal())
#data['date'] = pd.to_datetime(data['date'])

#Convert the date column index to type datetime
data.index = pd.to_datetime(data.index)

#Data preprocessing
data = data.dropna()
data = data[data['precipitation'] >= 0]
data = data[data['temperature'] > 0]
data = data[data['humidity'] >= 0]
data = data[data['evapotranspiration'] >= 0]
data = data[data['soil_moisture'] >= 0]

#Create training set and test set
train_size = int(len(data) * 0.8)
train_data = data.iloc[:train_size, :]

#Data normalization
scaler = MinMaxScaler()
train_scaled = scaler.fit_transform(train_data)

#Creation of sequences for training
n_steps = 30
X_train, y_train = [], []
for i in range(n_steps, len(train_scaled)):
    X_train.append(train_scaled[i-n_steps:i, :-1])
    y_train.append(train_scaled[i, -1])
X_train, y_train = np.array(X_train), np.array(y_train)

#Creation of LSTM model
model = Sequential()
model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))
model.add(Dropout(0.2))
model.add(LSTM(units=50, return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(units=50, return_sequences=True))  # Se agrega una capa LSTM adicional
model.add(Dropout(0.2))
model.add(LSTM(units=50))
model.add(Dropout(0.2))
model.add(Dense(units=1))

#Build and train the model
model.compile(optimizer='rmsprop', loss='mean_squared_error')
model.fit(X_train, y_train, epochs=100, batch_size=32)

#Create test set
test_data = data.iloc[train_size-n_steps:, :]
test_data = test_data[test_data['date'] > test_data.iloc[0]['date']]
test_data_scaled = scaler.transform(test_data)

#Creating sequences for testing
X_test, y_test = [], []
for i in range(n_steps, len(test_data_scaled)):
    X_test.append(test_data_scaled[i-n_steps:i, :-1])
    y_test.append(test_data_scaled[i, -1])
X_test, y_test = np.array(X_test), np.array(y_test)

#Prediction of values
y_pred = model.predict(X_test)
#print(y_pred)

#Inverse transformation of the data to its original scale
y_pred_reshaped = y_pred.reshape(-1, 1)
zeros = np.zeros((X_test.shape[0], 1))
y_pred_inv = scaler.inverse_transform(np.concatenate((X_test[:, -1, :-1], zeros, y_pred), axis=1))[:, -1]

#Identification of droughts
umbral = 0.3
y_pred_reshaped = y_pred.reshape(-1, 1)
sequias = np.where(y_pred_reshaped > umbral)[0]
print('Number of records with drought:', len(sequias))

# Calculation of the prediction error
rmse = np.sqrt(mean_squared_error(test_data['soil_moisture'].iloc[n_steps:], y_pred_inv))
rmse = np.sqrt(mean_squared_error(test_data['soil_moisture'].iloc[n_steps:], y_pred_inv))
mae = mean_absolute_error(test_data['soil_moisture'].iloc[n_steps:], y_pred_inv)
r2 = r2_score(test_data['soil_moisture'].iloc[n_steps:], y_pred_inv)

# Create statistics summary table
table = PrettyTable()
table.field_names = ["Métrica", "Valor"]
table.add_row(["RMSE", round(rmse, 4)])
table.add_row(["MAE", round(mae, 4)])
table.add_row(["R^2", round(r2, 4)])

# print summary table
print(table)

"""
#Display the results
plt.figure(figsize=(12,6))
plt.plot(test_data['date'].iloc[n_steps:], test_data['soil_moisture'].iloc[n_steps:], label='Valor real')
plt.plot(test_data['date'].iloc[n_steps:], y_pred_inv, label='Predicción')
plt.xlabel('Fecha')
plt.ylabel('Humidity of floor')
plt.legend()
plt.show()
"""

# Add column with predicted drought values to test_data
test_data.loc[test_data.index[:len(y_pred_inv)], 'sequia_pred'] = y_pred_inv

# Create a drought column with binary values (1 if there was a drought, 0 if not)
test_data['sequia'] = np.where(test_data['sequia_pred'] > umbral, 1, 0)

# Group the data by year and count the number of records with and without drought
sequia_por_anio = test_data.groupby(test_data.index.year)['sequia'].value_counts().unstack().fillna(0)
print(sequia_por_anio)

# Convert index to date format
data.index = pd.to_datetime(data.index, format='%Y')

# Create a list with the years
years = list(data.index.year)

# Create a list with the values of records with drought
sequia = list(sequia_por_anio.loc[:, 1])

# Create a list with the values of records without drought
no_sequia = list(sequia_por_anio.loc[:, 0])

# Create a list with the years (excluding 1975)
years = list(range(2000, 2023))

# Create a figure and a set of axes
fig, ax = plt.subplots()

# Create the bars for the records without drought
ax.bar(years, no_sequia, color='blue')

# Create the bars for the records with drought
ax.bar(years, sequia, bottom=no_sequia, color='red')

# Add tags and title
ax.set_ylabel('Number of records')
ax.set_xlabel('Años')
ax.set_title('Registros con y sin sequía por año')
ax.set_xlim(min(years), max(years))

# show the graph
plt.show()
"""
# Plot the drought forecast versus the actual data
plt.plot(test_data.index[n_steps:], test_data['soil_moisture'].iloc[n_steps:], label='Datos reales')
plt.plot(test_data.index[n_steps:], y_pred_inv, label='Predicción')
plt.fill_between(test_data.index[n_steps:], 0, 1, where=y_pred_reshaped.flatten() > umbral, alpha=0.3, color='red', label='Sequía predicha')
plt.xlabel('Date')
plt.ylabel('Humidity of floor')

# Set X axis labels every 4 years
start_year = test_data.index[n_steps:].year.min()
end_year = test_data.index[n_steps:].year.max()
tick_years = range(start_year, end_year+1, 4)
tick_locs = pd.date_range(start='2000-01-01', end='2023-01-01', freq='4YS')
tick_labels = [x.strftime('%Y') for x in tick_locs if mdates.date2num(x).is_integer()]

fig, ax = plt.subplots()
ax.xaxis.set_major_locator(mticker.FixedLocator(tick_locs))
plt.xticks(tick_locs, tick_labels)

plt.plot(test_data.index[n_steps:], test_data['soil_moisture'].iloc[n_steps:], label='Datos reales')
plt.plot(test_data.index[n_steps:], y_pred_inv, label='Predicción')
plt.fill_between(test_data.index[n_steps:], 0, 1, where=y_pred_reshaped.flatten() > umbral, alpha=0.3, color='red', label='Sequía predicha')
plt.xlabel('Date')
plt.ylabel('Humidity of floor')
plt.legend()
plt.show()

# Generate the projection
n_steps = len(X_test)
future_steps = 12  # number of future steps to predict
future_dates = pd.date_range(start=test_data.index[n_steps], periods=future_steps+1, freq='MS')[1:]
future_X = test_data.iloc[-n_steps:][['rainfall', 'temperature']].values.reshape(1, n_steps, 2)
future_preds = []
for i in range(future_steps):
    future_pred = model.predict(future_X)[0, -1, 0]
    future_preds.append(future_pred)
    future_X = np.append(future_X[:, 1:, :], [[future_pred, 0]], axis=1)

# Convert the predictions to the original scale
future_preds_inv = scaler.inverse_transform(np.array(future_preds).reshape(-1, 1)).flatten()

# Plot the drought projection versus the actual data
plt.plot(test_data.index[n_steps:], test_data['soil_moisture'].iloc[n_steps:], label='Datos reales')
plt.plot(future_dates, future_preds_inv, label='Proyección')
plt.fill_between(test_data.index[n_steps:], 0, 1, where=y_pred_reshaped.flatten() > umbral, alpha=0.3, color='red', label='Sequía predicha')
plt.xlabel('Date')
plt.ylabel('Humidity of floor')
"""

# Calculate root mean square error
rmse = np.sqrt(mean_squared_error(y_test, y_pred_reshaped))
print(rmse.shape)
print('RMSE:', rmse)

with open('C:/Users/William/Desktop/parpadeos/Datossequias/resultados.txt', 'w') as f:
    # Escribir los resultados en el archivo
    f.write('Métricas de evaluación:\n')
    f.write('RMSE: ' + str(round(rmse, 4)) + '\n')
    f.write('MAE: ' + str(round(mae, 4)) + '\n')
    f.write('R^2: ' + str(round(r2, 4)) + '\n')

# create scatter plot
print(X_test[:,0].shape)
print(y_test.shape)
plt.scatter(X_test[:,0], y_test, color='blue', label='Datos reales')
plt.scatter(X_test[:,0], y_pred, color='red', label='Datos predichos')

# configure the chart
plt.title('Relationship between the independent variable and the dependent variable')
plt.xlabel('Independent variable')
plt.ylabel('Dependent variable')
plt.legend(loc='upper left')

# show the graph
plt.show()

#Save model
model.save('modelo_lstm.h5')

#Save scaler object
X_scaler = MinMaxScaler(feature_range=(0, 1))
X_scaled = X_scaler.fit_transform(X)

import pickle
with open('scaler.pkl', 'wb') as f:
    pickle.dump(scaler, f)

#Save X_scaler object
with open('X_scaler.pkl', 'wb') as f:
    pickle.dump(X_scaler, f)

#Save object y_scaler
with open('y_scaler.pkl', 'wb') as f:
    pickle.dump(y_scaler, f)
